{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 001 Preprocess ECG\n",
    "\n",
    "### Purpose\n",
    "Purpose of this notebook is to preprocess the raw ECG data for the 'We Love Reading' study.\n",
    "\n",
    "- Neurokit2 package with a custom pipeline will be used for preprocessing\n",
    "- Segmentation is performed afterwards\n",
    "- QA figures will be exported for every partipant\n",
    "- The processed data will be exported\n",
    "\n",
    "\n",
    "### Input / Output\n",
    "- Input: `~/data/raw`\n",
    "- Outputs:\n",
    "  - QA visualizations: `~/reports/ECG QA`\n",
    "  - Processed data: `~/data/processed`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "from typing import Union, Tuple, Dict, Optional, List\n",
    "from pathlib import Path\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import nk_pipeline\n",
    "import neurokit2 as nk\n",
    "importlib.reload(nk)\n",
    "importlib.reload(nk_pipeline)\n",
    "import warnings\n",
    "import yaml\n",
    "# fmt:on\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = Path().cwd()\n",
    "ROOT_DIR = WORKING_DIR.parent\n",
    "DATA_DIR = ROOT_DIR / 'data'\n",
    "RAW_DATA_DIR = DATA_DIR / 'raw'\n",
    "PROCESSED_DATA_DIR = DATA_DIR / 'processed'\n",
    "PROCESSED_DATA_DIR.mkdir(parents=False, exist_ok=True)\n",
    "REPORTS_DIR = ROOT_DIR / 'reports'\n",
    "REPORTS_DIR.mkdir(parents=False, exist_ok=True) \n",
    "QA_REPORTS_DIR = REPORTS_DIR / 'QA'\n",
    "QA_REPORTS_DIR.mkdir(parents=False, exist_ok=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline config\n",
    "\n",
    "The pipeline config below is the standard config that will be applied to every dyad unless not otherwise specified using (e.g., `configure_params()` support function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_params = {\n",
    "    'general': {\n",
    "        'sampling_frequency': 500,\n",
    "        'analysis_window_seconds': 30,\n",
    "        'compute_hrv_frequency_metrics': False\n",
    "    },\n",
    "    'cleaning': {\n",
    "        'method': 'neurokit',\n",
    "        'powerline': None  # or 60 or None\n",
    "    },\n",
    "    'peak_detection': {\n",
    "        'method': 'neurokit',\n",
    "        'correct_artifacts': True\n",
    "    },\n",
    "    'signal_quality_index': {\n",
    "        'method': 'averageQRS',\n",
    "        'approach': 'simple'\n",
    "    },\n",
    "    'hrv_frequency_settings': {\n",
    "        'ulf': [0, 0.0033], # The spectral power of ultra low frequencies\n",
    "        'vlf': [0.0033, 0.04], # The spectral power of very low frequencies\n",
    "        'lf': [0.04, 0.15], # The spectral power of low frequencies\n",
    "        'hf': [0.15, 0.4],\n",
    "        'vhf': [0.4, 0.5], # The spectral power of very high frequencie\n",
    "        'psd_method': 'welch',\n",
    "        'normalize': True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_params(subject_id: str, pipeline_params: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Configures child and mother parameters based on the subject ID.\n",
    "\n",
    "    Args:\n",
    "        subject_id (str): The ID of the subject being processed.\n",
    "        pipeline_params (Dict): The base dictionary containing default pipeline parameters.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Dict, Dict]: A tuple containing customized dictionaries for child_params and mother_params.\n",
    "    \"\"\"\n",
    "    # Create deep copies to avoid modifying the original pipeline_params\n",
    "    child_params = pipeline_params.copy()\n",
    "    mother_params = pipeline_params.copy()\n",
    "    \n",
    "    # Customize parameters based on subject_id\n",
    "    # if subject_id == 8:\n",
    "    #     child_params['cleaning'].update({\"powerline\": 60})\n",
    "    # elif subject_id == \"4\":\n",
    "    #     mother_params['general'].update({\"key2\": \"value2\"})\n",
    "    \n",
    "    # Add more conditions for other subject IDs as needed\n",
    "\n",
    "    return child_params, mother_params\n",
    "\n",
    "def process_data_in_parallel(data_filepaths: List[Union[str, Path]], \n",
    "                             pipeline_params: Dict, \n",
    "                             processed_data_dir: Union[str, Path], \n",
    "                             qa_reports_dir: Union[str, Path]) -> None:\n",
    "    \"\"\"\n",
    "    Processes data files in parallel using multithreading, with error handling for exceptions.\n",
    "\n",
    "    Args:\n",
    "        data_filepaths (List[Union[str, Path]]): List of file paths for data files to process.\n",
    "        pipeline_params (Dict): Dictionary containing the base pipeline parameters.\n",
    "        processed_data_dir (Union[str, Path]): Directory for saving processed data.\n",
    "        qa_reports_dir (Union[str, Path]): Directory for saving quality assurance (QA) reports.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    processed_data_dir = Path(processed_data_dir)\n",
    "    qa_reports_dir = Path(qa_reports_dir)\n",
    "\n",
    "    def process_single_subject(filepath: Union[str, Path]):\n",
    "        try:\n",
    "            print(f\"Processing {filepath}\")\n",
    "            filepath = Path(filepath)\n",
    "            subject_id, condition = nk_pipeline.extract_subject_id_condition_from_filepath(filepath)\n",
    "            \n",
    "            # Configure parameters based on subject_id\n",
    "            child_params, mother_params = configure_params(subject_id, pipeline_params)\n",
    "            \n",
    "            # Process each subject data file\n",
    "            nk_pipeline.process_subject(\n",
    "                filepath, \n",
    "                child_params, \n",
    "                mother_params, \n",
    "                processed_data_dir, \n",
    "                qa_reports_dir\n",
    "            )\n",
    "            print(f\"Successfully processed {filepath}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filepath}: {e}\")\n",
    "            raise  # Re-raise the exception to capture it in the future\n",
    "\n",
    "    # Use ThreadPoolExecutor to process each subject in parallel\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        futures = {executor.submit(process_single_subject, filepath): filepath for filepath in data_filepaths}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            filepath = futures[future]\n",
    "            try:\n",
    "                future.result()  # Retrieve the result to trigger any exceptions\n",
    "            except Exception as e:\n",
    "                print(f\"Error occurred for {filepath}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "Extract data filepaths for the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/C08_mc.txt\n",
      "/Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/B08_mc.txt\n",
      "/Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/B32_mc.txt\n",
      "/Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/C32_mc.txt\n",
      "/Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/W32_mc.txt\n",
      "/Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/W08_mc.txt\n",
      "(8, 'C')\n",
      "(8, 'B')\n",
      "(32, 'B')\n",
      "(32, 'C')\n",
      "(32, 'W')\n",
      "(8, 'W')\n"
     ]
    }
   ],
   "source": [
    "data_filepaths = list(RAW_DATA_DIR.glob('*mc.txt'))\n",
    "[print(f) for f in data_filepaths];\n",
    "[print(nk_pipeline.extract_subject_id_condition_from_filepath(f)) for f in data_filepaths];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/C08_mc.txt\n",
      "Processing /Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/B08_mc.txt\n",
      "Processing /Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/B32_mc.txt\n",
      "Processing /Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/C32_mc.txt\n",
      "Processing /Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/W32_mc.txt\n",
      "Processing /Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/W08_mc.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasspiess/anaconda3/envs/neuroprofile/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/lukasspiess/anaconda3/envs/neuroprofile/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/lukasspiess/anaconda3/envs/neuroprofile/lib/python3.10/site-packages/neurokit2/hrv/hrv_time.py:168: RuntimeWarning: Mean of empty slice\n",
      "  out[\"RMSSD\"] = np.sqrt(np.nanmean(diff_rri**2))\n",
      "/Users/lukasspiess/anaconda3/envs/neuroprofile/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/lukasspiess/anaconda3/envs/neuroprofile/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/lukasspiess/anaconda3/envs/neuroprofile/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed /Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/B32_mc.txt\n",
      "Successfully processed /Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/C32_mc.txt\n",
      "Successfully processed /Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/C08_mc.txt\n",
      "Successfully processed /Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/W32_mc.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasspiess/anaconda3/envs/neuroprofile/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/Users/lukasspiess/anaconda3/envs/neuroprofile/lib/python3.10/site-packages/neurokit2/hrv/hrv_time.py:168: RuntimeWarning: Mean of empty slice\n",
      "  out[\"RMSSD\"] = np.sqrt(np.nanmean(diff_rri**2))\n",
      "/Users/lukasspiess/anaconda3/envs/neuroprofile/lib/python3.10/site-packages/numpy/lib/nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully processed /Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/B08_mc.txt\n",
      "Successfully processed /Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Documents - We Love Reading/Welcome/data/raw/W08_mc.txt\n"
     ]
    }
   ],
   "source": [
    "process_data_in_parallel(data_filepaths, pipeline_params, PROCESSED_DATA_DIR, QA_REPORTS_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = data_filepaths[1]\n",
    "# process_subject(file, pipeline_params, pipeline_params, PROCESSED_DATA_DIR, QA_REPORTS_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroprofile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
