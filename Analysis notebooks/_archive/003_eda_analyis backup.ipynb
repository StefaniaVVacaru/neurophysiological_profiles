{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 003 EDA Analysis\n",
    "\n",
    "### Purpose\n",
    "\n",
    "Purpose of this notebook is to analyse the Mindware EDA data \n",
    "\n",
    "### Approach\n",
    "- Preprocess the EDA signal data\n",
    "- Segment the EDA signal\n",
    "- Extract features\n",
    "- Baseline correct\n",
    "\n",
    "### Input <> Output\n",
    "\n",
    "- Input `~/data/interim/signals`\n",
    "- Processed data output (including metrics): `~/data/processed/eda`\n",
    "- QA figures Output: `~reports/QA/eda`\n",
    "- Aggregated metrics `~data/final/eda`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'ecg_utils.parameters' from '/Users/lukasspiess/Library/CloudStorage/OneDrive-SpiessSolution/Neurophysiological profiles/General/Mindware data analysis/src/ecg_utils/parameters.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fmt: off\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from typing import List, Dict, Any, Optional, Union\n",
    "import pandas as pd \n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.collections\n",
    "import numpy as np\n",
    "import warnings\n",
    "import neurokit2 as nk\n",
    "sys.path.append(str(Path().cwd().parent/\"src\"))\n",
    "sys.path.append(str(Path().cwd().parent/\"app\"))\n",
    "import ecg_utils.data_utils as data_utils\n",
    "import ecg_utils.parameters as parameters\n",
    "importlib.reload(data_utils)\n",
    "importlib.reload(parameters)\n",
    "# fmt: on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = Path().cwd()\n",
    "ROOT_DIR = WORKING_DIR.parent\n",
    "\n",
    "DATA_DIR = ROOT_DIR / 'data'\n",
    "INTERIM_SIGNAL_DATA_DIR = DATA_DIR / 'interim' / 'signals'\n",
    "\n",
    "PROCESSED_DATA_DIR = DATA_DIR / 'processed' / 'eda'\n",
    "PROCESSED_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FINAL_DATA_DIR = DATA_DIR / 'final' / 'eda_features'\n",
    "FINAL_DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "QA_REPORTS_DIR = ROOT_DIR / 'reports' / 'QA' / 'eda'\n",
    "QA_REPORTS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_rate = 500\n",
    "base_parameters = parameters.base_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_zscore(\n",
    "    df: pd.DataFrame,\n",
    "    column: str,\n",
    "    z_threshold: float,\n",
    "    window_size: int\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Detects outliers in a specified column using the z-score method \n",
    "    for non-overlapping windows.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input data frame.\n",
    "        column (str): The column name for which to compute outliers.\n",
    "        z_threshold (float): The z-score threshold for outlier detection.\n",
    "        window_size (int): The size of the non-overlapping windows.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The original data frame with two new columns:\n",
    "                      - 'is_outlier': Indicates if the value is an outlier (True/False).\n",
    "                      - 'z_score': The computed z-score for each value.\n",
    "    \"\"\"\n",
    "    # Ensure the column exists\n",
    "    if column not in df.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found in the DataFrame.\")\n",
    "\n",
    "    # Create a new column to assign non-overlapping groups\n",
    "    df['group'] = df.index // window_size\n",
    "\n",
    "    # Function to compute z-scores and detect outliers within each group\n",
    "    def compute_outliers(group):\n",
    "        values = group[column]\n",
    "        mean = values.mean()\n",
    "        std = values.std()\n",
    "\n",
    "        # Avoid division by zero\n",
    "        if std == 0:\n",
    "            group['z_score'] = 0\n",
    "            group['is_outlier'] = False\n",
    "        else:\n",
    "            group['z_score'] = (values - mean) / std\n",
    "            group['is_outlier'] = group['z_score'].abs() > z_threshold\n",
    "        return group\n",
    "\n",
    "    # Apply the outlier detection function to each group\n",
    "    df = df.groupby('group').apply(compute_outliers)\n",
    "\n",
    "    # Drop the temporary 'group' column\n",
    "    df.drop(columns=['group'], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def plot_thresholded_z_scores(df, threshold, filename, sampling_rate:int=500):\n",
    "    \"\"\"\n",
    "    Plots the given data and saves the plot to a file.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame containing the data to be plotted. \n",
    "                            It should have columns 'MWMOBILEJ_GSC' and 'z_score'.\n",
    "    threshold (float): The threshold value to be plotted as a horizontal line on the z-score plot.\n",
    "    filename (str): The path and name of the file where the plot will be saved.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(nrows=2, ncols =1,figsize=(15, 5))\n",
    "    ax[0].plot(df.index / sampling_rate ,df['MWMOBILEJ_GSC'], color = 'black')\n",
    "    ax[0].set_ylabel('Microsiemens')\n",
    "    ax[1].plot(df.index / sampling_rate ,df['z_score'].abs(), color = 'black')\n",
    "    ax[1].set_ylabel('z-score')\n",
    "    ax[1].axhline(y=threshold, color='darkred', linestyle='--', label = 'Threshold')\n",
    "    ax[1].set_xlabel('Time (s)')\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_segments(segment_df_list: List[pd.DataFrame], sampling_rate: int = 500) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract features from a list of physiological data segments.\n",
    "\n",
    "    This function processes a list of dataframes, each containing physiological data\n",
    "    for a specific segment, and extracts features using NeuroKit2's EDA analysis.\n",
    "    The extracted features are complemented with metadata such as segment name,\n",
    "    subject ID, and additional calculated metrics.\n",
    "\n",
    "    Args:\n",
    "        segment_df_list (List[pd.DataFrame]): \n",
    "            A list of dataframes where each dataframe represents a segment of \n",
    "            physiological data. Each dataframe must include columns `event_name` \n",
    "            and `subject_id` to identify the segment and subject, respectively.\n",
    "        sampling_rate (int, optional): \n",
    "            Sampling rate of the physiological data in Hz. Defaults to 500.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: \n",
    "            A dataframe containing the extracted features for all segments, \n",
    "            enriched with metadata and calculated metrics such as \n",
    "            `segment_name`, `subject_id`, `segment_length_seconds`, \n",
    "            and `SCR_Peaks_N_per_seconds`.\n",
    "\n",
    "    Raises:\n",
    "        KeyError: \n",
    "            If `event_name` or `subject_id` is missing in the input dataframes.\n",
    "        ValueError: \n",
    "            If the input segment list is empty or the segment dataframes are malformed.\n",
    "    \"\"\"\n",
    "    results_df = pd.DataFrame()\n",
    "    for segment_df in segment_df_list:\n",
    "        # assign some variables\n",
    "        segment_name = segment_df[\"event_name\"].unique()[0]\n",
    "        subject_id = segment_df[\"subject_id\"].unique()[0]\n",
    "        segment_length_seconds = len(segment_df) / sampling_rate\n",
    "        # extract features\n",
    "        features_df = nk.eda_analyze(segment_df, sampling_rate=sampling_rate, method=\"interval-related\")\n",
    "        # complement df with additional information\n",
    "        features_df = features_df.assign(\n",
    "            segment_name=segment_name, \n",
    "            subject_id=subject_id,\n",
    "            segment_length_seconds=segment_length_seconds,\n",
    "            SCR_Peaks_N_per_seconds=features_df[\"SCR_Peaks_N\"] / segment_length_seconds,\n",
    "            )\n",
    "        # concatenate results   \n",
    "        results_df = pd.concat([results_df, features_df])\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eda_plot(\n",
    "    eda_signals: pd.DataFrame, info_dict: dict, sampling_rate: int = 500\n",
    ") -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Simplified visualization of electrodermal activity (EDA) data with SCR peaks.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    eda_signals : pd.DataFrame\n",
    "        DataFrame containing columns 'EDA_Raw', 'EDA_Clean', 'EDA_Phasic', and 'EDA_Tonic'.\n",
    "    info_dict : dict\n",
    "        Dictionary containing SCR information with keys 'SCR_Peaks' and optionally others.\n",
    "    sampling_rate : int, optional\n",
    "        Sampling rate of the EDA signal, in Hz. Defaults to 1000.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    plt.Figure\n",
    "        Matplotlib figure object.\n",
    "    \"\"\"\n",
    "    required_columns = ['EDA_Raw', 'EDA_Clean', 'EDA_Phasic', 'EDA_Tonic']\n",
    "    if not all(col in eda_signals.columns for col in required_columns):\n",
    "        raise ValueError(f\"Input DataFrame must contain the following columns: {required_columns}\")\n",
    "\n",
    "    if \"SCR_Peaks\" not in info_dict:\n",
    "        raise ValueError(\"info_dict must contain the key 'SCR_Peaks'.\")\n",
    "\n",
    "    # Create time axis\n",
    "    x_axis = np.linspace(0, len(eda_signals) / sampling_rate, len(eda_signals))\n",
    "    x_label = \"Time (seconds)\"\n",
    "    peaks_seconds = np.array(info_dict[\"SCR_Peaks\"]) / sampling_rate\n",
    "\n",
    "    # Create subplots\n",
    "    fig, (ax0, ax1, ax2) = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=(10, 8))\n",
    "\n",
    "    # Plot Raw and Cleaned Signal\n",
    "    ax0.set_title(\"Raw and Cleaned Signal\")\n",
    "    ax0.plot(x_axis, eda_signals[\"EDA_Raw\"], color=\"#B0BEC5\", label=\"Raw\", zorder=1)\n",
    "    ax0.plot(x_axis, eda_signals[\"EDA_Clean\"], color=\"#9C27B0\", label=\"Cleaned\", linewidth=1.5, zorder=2)\n",
    "    ax0.legend(loc=\"upper right\")\n",
    "    ax0.set_ylabel(\"EDA (µS)\")\n",
    "\n",
    "    # Plot Phasic Component\n",
    "    ax1.set_title(\"Phasic Component\")\n",
    "    ax1.plot(x_axis, eda_signals[\"EDA_Phasic\"], color=\"#E91E63\", label=\"Phasic\", linewidth=1.5)\n",
    "    # Mark SCR peaks with vertical lines\n",
    "    for peak in peaks_seconds:\n",
    "        ax1.axvline(x=peak, color='blue', linestyle='--', alpha=0.7, label=\"SCR Peak\" if peak == peaks_seconds[0] else None)\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.set_ylabel(\"EDA (µS)\")\n",
    "\n",
    "    # Plot Tonic Component\n",
    "    ax2.set_title(\"Tonic Component\")\n",
    "    ax2.plot(x_axis, eda_signals[\"EDA_Tonic\"], color=\"#673AB7\", label=\"Tonic\", linewidth=1.5)\n",
    "    ax2.legend(loc=\"upper right\")\n",
    "    ax2.set_xlabel(x_label)\n",
    "    ax2.set_ylabel(\"EDA (µS)\")\n",
    "\n",
    "    fig.suptitle(\"Electrodermal Activity (EDA)\", fontweight=\"bold\")\n",
    "\n",
    "    # Adjust layout\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse EDA\n",
    "\n",
    "For each subject:\n",
    "\n",
    "1. Read data\n",
    "2. preprocess using neurokit2 (and export the preprocessed data)\n",
    "3. Create QA plots with tonic and phasic signal (export)\n",
    "4. Segment\n",
    "5. Extract features (and export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data files\n",
    "data_files_generator = INTERIM_SIGNAL_DATA_DIR.glob('*.csv')\n",
    "print(f\"Identified {data_files_generator.__sizeof__()} data files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for signal_filepath in data_files_generator:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        signal_df = pd.read_csv(signal_filepath)\n",
    "        if not 'MWMOBILEJ_GSC' in signal_df.columns:\n",
    "            print(f\"Skipping {signal_filepath} as it does not contain the required column 'MWMOBILEJ_GSC'\")\n",
    "            continue\n",
    "        signal_df = signal_df.drop(columns = \"MWMOBILEJ_Bio\")\n",
    "    subject_id = str(signal_df['subject_id'].unique()[0])\n",
    "    print(f\"Processing data for subject {subject_id}\")\n",
    "    \n",
    "    # Preprocess and join with original data\n",
    "    signal_preproc_df, info_dict = nk.eda_process(signal_df[\"MWMOBILEJ_GSC\"], sampling_rate=sampling_rate, report=None)\n",
    "    signal_df = (signal_df\n",
    "                 .drop(columns=['MWMOBILEJ_GSC'])\n",
    "                 .merge(signal_preproc_df, left_index=True, right_index=True))\n",
    "    \n",
    "    # Create QA plot of the entire recoding and export it\n",
    "    eda_plot(signal_preproc_df,info_dict, 500);\n",
    "    plt.savefig(QA_REPORTS_DIR / f'{subject_id}_eda.png')\n",
    "    \n",
    "    # Segment\n",
    "    segments_df_list = data_utils.segment_df(signal_df, base_parameters)\n",
    "    \n",
    "    # Extract features\n",
    "    features_df = extract_features_from_segments(segments_df_list, sampling_rate=sampling_rate)\n",
    "    \n",
    "    # save the pre-processed signal data and the extracted features \n",
    "    output_dir = PROCESSED_DATA_DIR / subject_id\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    signal_df.to_csv(output_dir / 'preprocessed_eda.csv', index=False)\n",
    "    features_df.to_excel(output_dir / 'eda_features.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the EDA features, baseline correct and export as group-level file\n",
    "\n",
    "1. Read the EDA features of a subject\n",
    "2. Perform baseline correction\n",
    "3. Concatenate the data from each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folders_in_directory(directory_path: Union[str,Path]) -> list[Path]:\n",
    "    \"\"\"\n",
    "    Get all folders in the specified directory.\n",
    "\n",
    "    Args:\n",
    "        directory_path (str): The path of the directory to scan for folders.\n",
    "\n",
    "    Returns:\n",
    "        list[Path]: A list of Path objects representing folders in the directory.\n",
    "    \"\"\"\n",
    "    path = Path(directory_path)\n",
    "    return [item for item in path.iterdir() if item.is_dir()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_baseline_correction(features_df: pd.DataFrame, ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies baseline correction to physiological feature data by subtracting\n",
    "    baseline values for specified features from the corresponding segment data.\n",
    "\n",
    "    Args:\n",
    "        features_df (pd.DataFrame): \n",
    "            A dataframe containing extracted features with a `segment_name` column \n",
    "            identifying the segment type (e.g., \"Baseline\") and a `subject_id` column \n",
    "            for identifying the subject.\n",
    "   \n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: \n",
    "            A dataframe with baseline-corrected metrics, where baseline values \n",
    "            have been subtracted from the corresponding features. The output \n",
    "            excludes rows where `segment_name` is \"Baseline\" and removes \n",
    "            the original feature columns and baseline values.\n",
    "    \"\"\"\n",
    "    #\n",
    "    feature_cols = [\"SCR_Peaks_Amplitude_Mean\",\t\"EDA_Tonic_SD\",\t\"EDA_Sympathetic\", \"EDA_SympatheticN\",\t\"EDA_Autocorrelation\", \"SCR_Peaks_N_per_seconds\", \"SCR_Peaks_N\"]\n",
    "    # Prepare the data\n",
    "    group_level_metrics_df = features_df.reset_index()\n",
    "    baseline_df = group_level_metrics_df[group_level_metrics_df[\"segment_name\"] == \"Baseline\"].set_index(\"subject_id\")\n",
    "\n",
    "    # Merge baseline values with the original DataFrame\n",
    "    df = group_level_metrics_df.merge(\n",
    "        baseline_df[feature_cols],\n",
    "        on=\"subject_id\",\n",
    "        suffixes=(\"\", \"_baseline\")\n",
    "    )\n",
    "\n",
    "    # Apply baseline correction\n",
    "    for col in feature_cols:\n",
    "        df[f\"{col}_blc\"] = df[col] - df[f\"{col}_baseline\"]\n",
    "\n",
    "    # # Drop unneeded columns\n",
    "    # df = df.drop(columns=feature_cols + ['index']) #  + [f\"{col}_baseline\" for col in feature_cols]\n",
    "\n",
    "    # Filter out baseline rows\n",
    "    baseline_corrected_metrics_df = df[df[\"segment_name\"] != \"Baseline\"]\n",
    "\n",
    "    return baseline_corrected_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_subject_folders = get_folders_in_directory(PROCESSED_DATA_DIR)\n",
    "group_level_features_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for subject_folder in processed_subject_folders:\n",
    "    subject_id = subject_folder.parts[-1]\n",
    "    # print(f\"Processing subject {subject_id}\")\n",
    "    features_df = pd.read_excel(subject_folder / 'eda_features.xlsx')\n",
    "    group_level_features_df = pd.concat([group_level_features_df, features_df])\n",
    "    \n",
    "# Apply baseline correction\n",
    "baseline_corrected_df = apply_baseline_correction(group_level_features_df)\n",
    "baseline_corrected_df.to_excel(FINAL_DATA_DIR / 'group_level_blc_eda_features.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroprofile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
